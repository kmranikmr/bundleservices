import digdag
import os
from datetime import time, datetime
import psycopg2
from objectpath.utils.timeutils import now
from pandas import DataFrame
from psycopg2.extras import RealDictCursor
from sqlalchemy import MetaData
from sqlalchemy import create_engine
from sqlalchemy import event
from io import BytesIO
import dill,base64,tempfile
from joblib import load
import pickle
from keras.models import model_from_json
import pandas as pd
import datetime
import yfinance as yf

DATABASE_NAME = os.getenv('DATABASE_NAME')
DATABASE_USER = os.getenv('DATABASE_USER')
DATABASE_PASSWORD = os.getenv('DATABASE_PASSWORD')
DATABASE_HOST = os.getenv('DATABASE_HOST')
DATABASE_PORT = os.getenv('DATABASE_PORT')
AWS_ACCESS_KEY_ID = os.getenv('AWS_ACCESS_KEY_ID')
AWS_SECRET_ACCESS_KEY = os.getenv('AWS_SECRET_ACCESS_KEY')

def run_id():
    if 'sessionIds' in  digdag.env.params:
        sessiondIdvalue = digdag.env.params["sessionIds"]
    else:
        sessiondIdvalue = ""

    if not sessiondIdvalue:
       return ""
    else:
       str = sessiondIdvalue.replace(',','_')
       return str
    return ""

def remove_temps(tables):
    con = psycopg2.connect(database=DATABASE_NAME, user=DATABASE_USER, password=DATABASE_PASSWORD, host=DATABASE_HOST, port=DATABASE_PORT)
    print("Database opened successfully for removal")
    cur = con.cursor()
    liststr = tables.split(',')
    for tabl in liststr:
        outstr = tabl + "{}".format(run_id())
        drop_sql = """drop table if exists public.%s;"""%outstr
        print(drop_sql)
        cur.execute(drop_sql)
        print("droped " + drop_sql)
    con.commit()
    cur.close()
    con.close()
    print("droped " + tables)


def do_transformation(df):
    df = process_custom_code(df)
    outstr = "[NODENAME]{}_[NODEID]".format(run_id())
    print("process custom code done")
    print(outstr)
    if isinstance(df, pd.DataFrame):
       insert_data_postgres(df,outstr , 'public')


def insert_data_postgres(df, table_name, schema):
    dbschema = schema
    engine = create_engine('postgresql+psycopg2://ubuntu:dapdata123@digdagdb.cv1llisahmax.us-east-1.rds.amazonaws.com:5432/digdagdb',
                connect_args={'options': '-csearch_path={}'.format(dbschema)})

   
    df.to_sql(table_name, engine, if_exists='append', index=False)
    print("*", end = '')
    engine.dispose()
    return True
#input from saved query



[COMMANDBODY]

def [METHODNAME]():
    [REMOVEALL_TEMP]
    if 'sessionIds' in  digdag.env.params:
       sessiondIdvalue = digdag.env.params["sessionIds"]
    else:
       sessiondIdvalue = ""
    
    print("sessiondIdvalue " + sessiondIdvalue)
    input_query = ""
    
    print("input_query" + input_query)
    #we will add the saved query in the nnniput query...
    df = pd.DataFrame()
    do_transformation(df)


if __name__ == "__main__":
    [METHODNAME]()

